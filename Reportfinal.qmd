---
title: "Data Analytics Final Project"
author: 
  - Trifanov Matvei
  - Pasindu Perera
abstract: "In this project we analyzed flight data from New York City airports to uncover key factors influencing flight delays and build predictive models for both regression and classification tasks. Using five datasets containing flight details, weather conditions, airline information, and more, we conducted thorough data cleaning, preprocessing, and exploratory analysis to ensure data quality and uncover meaningful insights. For the regression task, we focused on predicting flight arrival delays (arr_delay) based on features such as flight distance, weather variables, and airline carriers. Our refined regression model, evaluated using metrics like RMSE and MAE, provided insights into the key contributors to delays, though inherent variability in the data posed challenges. A classification task was also undertaken to categorize flights, offering additional perspectives on the data. Overall, this project demonstrates the application of supervised learning techniques to real-world data, highlighting both the opportunities and limitations of predictive modeling in complex domains."
format:   
  html: 
    toc: true
    toc-depth: 3
    standalone: true
    embed-resources: true
    code-fold: true
    number-sections: true
editor: 
  markdown: 
    wrap: sentence
---

```{r}
#| label: packages-data
#| message: false
#| echo: false
library(tidymodels)
library(tidyverse)
library(patchwork)
library(ggplot2)
library(dplyr)
library(glue)
library(knitr)
library(corrr)
library(naniar)
library(scales)
library(ggtext)  
library(forcats)
library(ggcorrplot)
library(corrplot)
library(lubridate)
library(fastDummies)
library(caret)
library(pROC)
```

```{r}
#| label: data_load
airlines = read.csv("Data/airlines.csv", sep = ";", header = TRUE)
airports = read.csv("Data/airports.csv", sep = ";", header = TRUE)
flights = read.csv("Data/flights.csv", sep = ";", header = TRUE)
planes = read.csv("Data/planes.csv", sep = ";", header = TRUE)
weather = read.csv("Data/weather.csv", sep = ";", header = TRUE)
```

## Introduction

This project uses dataframes about flights, specifically a sample of domestic flights departing from the three major New York City airports in 2023.

There are 5 tabular dataframes.
Some frequencies statistics:\
`r nrow(airlines)` **airlines**,\
`r nrow(airports)` **airports**,\
`r nrow(flights)` **flights**,\
`r nrow(planes)` **planes**,\
`r nrow(weather)` **weather** observations.

The main dataframe `flights` has the following variables:

`year`, `month`, `day`: Date of departure.\
`dep_time`, `arr_time`: Actual departure and arrival times (format HHMM or HMM), local time zone.\
`sched_dep_time`, `sched_arr_time`: Scheduled departure and arrival times (format HHMM or HMM), local time zone.\
`dep_delay`, `arr_delay`: Departure and arrival delays, in minutes.
Negative times represent early departures/arrivals.\
`carrier`: Two letter carrier abbreviation.
See `airlines` dataframe to get the full name.\
`flight`: Flight number.\
`tailnum`: Plane tail number.
See `planes` for additional metadata.\
`origin`, `dest`: Origin and destination.
See `airports` for additional metadata.\
`air_time`: Amount of time spent in the air, in minutes.\
`distance`: Distance between airports, in miles.\
`hour`, `minute`: Time of scheduled departure broken into hour and minutes.\
`time_hour`: Scheduled date and hour of the flight as a *POSIXct* date.
Along with *origin*, can be used to join flights data to `weather` data.

## Data Cleaning

In this project, we used a structured strategy to handle missing values across datasets, carefully balancing data preservation and noise.
For instance, datasets with many variables with missing values, such as `flights` and `weather`, we developed a threshold.

-   Remove rows in which all critical variables are missing.
    These rows contain no useful information and add little to the analysis.

-   Impute rows with partial missing values: In rows where only a few variables are missing (e.g., less than 50%), we used imputation to preserve the remaining information.

```{r}
#| label: missing_data
# there we check for missing values
# Calculate missing values for the flights dataset
flights_missing = colSums(is.na(flights))
flights_missing = data.frame(
  Column = names(flights_missing),
  Missing_Values = flights_missing
  )
# only columns with missing values
flights_missing = flights_missing[flights_missing$Missing_Values > 0, ]
rownames(flights_missing) = NULL
flights_missing |> kable(caption = "Missing values in the flights")

# calculating missing values for the weather
weather_missing = colSums(is.na(weather))
weather_missing = data.frame(
  Column = names(weather_missing),
  Missing_Values = weather_missing)
weather_missing = weather_missing[weather_missing$Missing_Values > 0, ]
rownames(weather_missing) = NULL
weather_missing |> kable(caption = "Missing values in weather")
```

For example, in the `weather` dataset, which contains missing values in 9 out of 16 variables:

-   Removed rows where 5 or more (≥50%) of the 9 variables were missing.

-   Retained and imputed rows where fewer than 5 variables were missing.
    Numerical variables were imputed using the mean, as it maintains the central tendency of the data without introducing bias.

This approach provides a good balance between data preservation and quality maintenance, guaranteeing that incomplete but valuable rows are not deleted unnecessarily while avoiding excessive imputation of very incomplete rows.

![](images/clipboard-2241566120.png)

```{r}
#| label: flights-cleaning
#| warning: false
get_mode = function(x) { # function to find the most frequent value (mode)
  ux = unique(na.omit(x)) 
  ux[which.max(tabulate(match(x, ux)))] 
}

### Flights cleaning

# Remove rows with missing critical values (dep_time or arr_time)
flights_cleaned <- flights %>% 
  filter(!is.na(dep_time) & !is.na(arr_time))

# Impute missing values for dep_time, arr_time, arr_delay, and air_time using medians
flights_cleaned <- flights_cleaned %>% 
  mutate(
    dep_time = ifelse(is.na(dep_time), median(dep_time, na.rm = TRUE), dep_time),
    arr_time = ifelse(is.na(arr_time), median(arr_time, na.rm = TRUE), arr_time),
    arr_delay = ifelse(is.na(arr_delay), median(arr_delay, na.rm = TRUE), arr_delay),
    air_time = ifelse(is.na(air_time), median(air_time, na.rm = TRUE), air_time)
  )

# Remove rows with missing tailnum and dep_delay
flights_cleaned <- flights_cleaned %>% 
  filter(!is.na(tailnum) & !is.na(dep_delay))

# Final Missing Count Check
missing_count_final <- colSums(is.na(flights_cleaned))
missing_count_final |> kable(caption = "Missing values in flights_cleaned")
```

```{r}
#| label: airports-cleaning
#| warning: false
### Airports cleaning
# we check what columns have missing values
# then we apply the aforementioned approach again 
# like we did for flights dataframe

# Remove rows where tzone, tz and dst are all missing
airports_clean = airports[!(is.na(airports$tz) & is.na(airports$dst) & is.na(airports$tzone)), ]

# Impute tz with the mode
airports_clean$tz[is.na(airports_clean$tz)] = get_mode(airports_clean$tz)

# impute tzone with the mode
airports_clean$tzone[is.na(airports_clean$tzone)] = get_mode(airports_clean$tzone)

# Impute dst U = Unknown
airports_clean$dst[is.na(airports_clean$dst)] = "U"

colSums(is.na(airports_clean)) |> kable(caption = "Missing values in airports_clean")
```

```{r}
#| label: planes-cleaning
#| warning: false
# 89 out of 4840 observations are missing
# they represent only ~1.8% of the data. Given this small percentage, imputing with the median is our choice
# Calculate and display the median year for reference
median_year = median(planes$year, na.rm = TRUE)
# Impute missing 'year' with the median value
planes_clean = planes
planes_clean$year[is.na(planes_clean$year)] = median_year

colSums(is.na(planes_clean)) |> kable(caption = "Missing values in planes_clean")
```

```{r}
#| label: weather-cleaning
#| warning: false
### Weather cleaning

# Again, we are following our approach by removing observations
# where >50% of variables are missing
key_weather_vars = c("temp", "dewp", "humid", "wind_dir", "wind_speed", "wind_gust", "precip", "pressure", "visib")

# Count missing values in key weather variables
weather$missing_count = rowSums(is.na(weather[, key_weather_vars]))

# Keep rows where <50% of variables are missing
weather_clean = weather[weather$missing_count <= (length(key_weather_vars) / 2), ]
weather_clean$missing_count = NULL  # no "help" column

# numerical variables imputation:
weather_clean$temp[is.na(weather_clean$temp)] = median(weather_clean$temp, na.rm = TRUE)
weather_clean$dewp[is.na(weather_clean$dewp)] = median(weather_clean$dewp, na.rm = TRUE)
weather_clean$humid[is.na(weather_clean$humid)] = median(weather_clean$humid, na.rm = TRUE)
weather_clean$pressure[is.na(weather_clean$pressure)] = median(weather_clean$pressure, na.rm = TRUE)
weather_clean$visib[is.na(weather_clean$visib)] = median(weather_clean$visib, na.rm = TRUE)

# wind variables imputation
weather_clean$wind_speed[is.na(weather_clean$wind_speed)] = mean(weather_clean$wind_speed, na.rm = TRUE)
weather_clean$wind_gust[is.na(weather_clean$wind_gust)] = mean(weather_clean$wind_gust, na.rm = TRUE)

# Imputing wind_dir (categorical) with the mode
weather_clean$wind_dir[is.na(weather_clean$wind_dir)] = get_mode(weather_clean$wind_dir)

# Imputing precip with 0 = no precipitation
weather_clean$precip[is.na(weather_clean$precip)] = 0

colSums(is.na(weather_clean)) |> kable(caption = "Missing values after cleaning weather dataset")

#pressure still has 920 NA values left
# it might not be recognized as numeric
# this could happen during import

str(weather_clean$pressure) # chr
#converting to numeric
weather_clean$pressure = as.numeric(weather_clean$pressure)
# finding median for pressure
pressure_median = median(weather_clean$pressure, na.rm = TRUE)
# Imputing
weather_clean$pressure[is.na(weather_clean$pressure)] = pressure_median

colSums(is.na(weather_clean)) |> kable(caption = "Misssing values in weather_clean")
```

## Exploratory Data Analysis

In the Exploratory Data Analysis (EDA) section, the focus is on summarizing and visualizing the dataset to uncover key patterns, relationships, and trends.
This process helps identify significant insights and supports the later modeling tasks.
Using visual tools such as bar charts, line plots, and correlation matrices, the EDA reveals variability in airline punctuality, the impact of weather conditions on flight delays, and delay trends across different destinations, timeframes, and carriers.
These insights lay a foundation for understanding the data and addressing the research questions effectively.

```{r}
#Average arrival delays by airline
flights_cleaned %>%
  group_by(carrier) %>%  # Group by carrier
  summarize(avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %>%  # Calculate average arrival delay
  left_join(airlines, by = c("carrier" = "carrier")) %>%  # Add airline names
  ggplot(aes(x = reorder(name, -avg_arr_delay), y = avg_arr_delay)) +  # Reorder airlines by delay
  geom_bar(stat = "identity", aes(fill = avg_arr_delay), show.legend = FALSE) +  # Color based on delay
  coord_flip() +  # Flip coordinates for better readability
  scale_fill_gradient(low = "lightcoral", high = "darkred") +  # Attractive gradient for bars
  geom_text(aes(label = round(avg_arr_delay, 1)), hjust = -0.2, size = 3) +  # Add labels on bars
  labs(
    title = "Airlines Ranked by Average Arrival Delay",
    subtitle = "Comparing average delays for domestic flights (in minutes)",
    x = "Airline",
    y = "Average Arrival Delay (minutes)"
  ) +
  theme_minimal(base_size = 14) +  # Modern theme with readable font size
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),  # Center and bold the title
    plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray50"),  # Add a styled subtitle
    axis.title.y = element_blank(),  # Remove y-axis title for simplicity
    axis.text.y = element_text(face = "bold"),  # Bold airline names for emphasis
    axis.ticks = element_blank(),  # Remove ticks for cleaner look
    panel.grid.major.x = element_line(color = "gray90"),  # Add light grid lines for x-axis
    panel.grid.major.y = element_blank()  # Remove grid lines for y-axis
  )
```

The chart ranks airlines by average arrival delays, with Allegiant Air showing the best performance (-5.9 minutes) and Frontier Airlines the worst (26.2 minutes).
It highlights variability in airline punctuality, with some airlines arriving early while others face significant delays.

```{r}
# Summarizing average delays by destination airport
flights_cleaned %>%
  group_by(dest) %>%  # Group by destination airport
  summarize(
    avg_dep_delay = mean(dep_delay, na.rm = TRUE),  # Calculate mean departure delay
    avg_arr_delay = mean(arr_delay, na.rm = TRUE),  # Calculate mean arrival delay
    num_flights = n()  # Count the number of flights
  ) %>%
  arrange(desc(avg_arr_delay)) %>%  # Sort by highest average arrival delay
  head(10) %>%  # Select the top 10 destination airports with the highest average arrival delays
  ggplot(aes(x = reorder(dest, -avg_arr_delay), y = avg_arr_delay)) +  # Reorder destinations by delay
  geom_bar(stat = "identity", aes(fill = avg_arr_delay), show.legend = FALSE) +  # Color based on delay
  coord_flip() +  # Flip coordinates for better readability
  scale_fill_gradient(low = "lightcoral", high = "darkred") +  # Attractive gradient for bars
  geom_text(aes(label = round(avg_arr_delay, 1)), hjust = -0.2, size = 3) +  # Add labels on bars
  labs(
    title = "Top 10 Destinations by Average Arrival Delay",
    subtitle = "Comparing average arrival delays for domestic destinations (in minutes)",
    x = "Destination Airport",
    y = "Average Arrival Delay (minutes)"
  ) +
  theme_minimal(base_size = 14) +  # Modern theme with readable font size
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),  # Center and bold the title
    plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray50"),  # Add a styled subtitle
    axis.title.y = element_blank(),  # Remove y-axis title for simplicity
    axis.text.y = element_text(face = "bold"),  # Bold destination airport names for emphasis
    axis.ticks = element_blank(),  # Remove ticks for cleaner look
    panel.grid.major.x = element_line(color = "gray90"),  # Add light grid lines for x-axis
    panel.grid.major.y = element_blank()  # Remove grid lines for y-axis
  )

```

The chart shows the top 10 domestic destinations with the highest average arrival delays.
Sacramento (SMF) has the shortest delay among these destinations (17.7 minutes), while Ponce (PSE) faces the highest average delay (37.3 minutes).
This analysis highlights airports with significant delays, offering insights for better resource allocation and scheduling.

```{r}
# Create an 'is_late' column to indicate whether a flight is late
flights_cleaned <- flights_cleaned %>%
  mutate(is_late = ifelse(arr_delay > 15, "1", "0"))  # "1" = Late, "0" = On-Time

# Plot proportion of flights by carrier classed by lateness
flights_cleaned %>%
  mutate(carrier = fct_reorder(
    .f = carrier,  # Carrier variable
    .x = is_late,  # Lateness variable
    .fun = function(.x) mean(.x == "1"),  # Proportion of late flights
    .desc = FALSE  # Sort in ascending order
  )) %>%
  ggplot(aes(x = carrier, fill = is_late)) +
  geom_bar(position = "fill", alpha = 0.9) +  # Bar chart with proportions and transparency
  geom_hline(yintercept = mean(flights_cleaned$is_late == "1"), 
             lty = 2, size = 1.2, col = "#7D7D7D") +  # Dashed average line in neutral gray
  annotate(geom = "label", x = 4, y = 0.25, 
           label = "Average Proportion", size = 5, 
           fill = "black", color = "white", fontface = "bold") +  # Annotation with styling
  labs(
    title = "<span style='color:#0073C2;'>Proportion of Flights by Carrier</span><br><b>Classed by Lateness</b>",
    x = "Carrier",
    y = "Proportion of Flights",
    fill = "Lateness"
  ) +
  scale_fill_manual(
    values = c("1" = "darkblue", "0" = "darkred"),  # Custom colors: Orange-red for late, blue-green for on-time
    labels = c("On-Time", "Late")  # Custom labels
  ) +
  theme_minimal(base_size = 14) +  # Minimal theme with larger base font
  theme(
    plot.title = element_markdown(size = 18, hjust = 0.5, face = "bold"),  # Enhanced title styling
    axis.title.x = element_text(size = 14, face = "bold"),  # Bold X-axis label
    axis.title.y = element_text(size = 14, face = "bold"),  # Bold Y-axis label
    axis.text = element_text(size = 12, face = "bold"),  # Bold axis text
    legend.title = element_text(size = 12, face = "bold"),  # Bold legend title
    legend.text = element_text(size = 11),  # Larger legend text
    panel.grid.major = element_line(color = "black", linetype = "dashed"),  # Subtle gridlines
    panel.grid.minor = element_blank()  # Hide minor gridlines
  )
```

The chart illustrates the proportion of flights classified as on-time or late for each airline carrier.
Green bars represent on-time flights, while red bars show late flights.
The dashed line indicates the average proportion of late flights across all carriers.
Airlines like G4 and YX have a higher proportion of on-time flights, whereas carriers like F9 and HA have a larger share of delayed flights, highlighting variability in punctuality across airlines.

```{r}
#Percentage of Late Flights by Origin Airport
flights_cleaned %>%
  group_by(origin, is_late) %>%  # Group by origin and lateness
  count() %>%  # Count number of flights
  ungroup() %>%  # Remove grouping for proportion calculation
  mutate(prop = n / sum(n)) %>%  # Calculate proportion
  filter(is_late == 1) %>%  # Filter for late flights
  ggplot(aes(x = reorder(origin, -prop), y = prop, fill = origin)) +
  geom_col(show.legend = FALSE, alpha = 0.9) +  # Bar chart with transparency
  geom_text(aes(label = paste0(round(prop * 100, 1), "%")), vjust = -0.5, size = 4, fontface = "bold") +  # Add percentage labels
  labs(
    title = "<b style='color:#0073C2;'>Percentage of Late Flights</b><br><b>By Origin Airport</b>",
    subtitle = "Proportion of flights arriving late (>15 minutes)",
    x = "Origin Airport",
    y = "Proportion of Late Flights",
      ) +
  scale_y_continuous(
    labels = label_percent(),  # Format Y-axis as percentages
    limits = c(0, 0.08)  # Set Y-axis range to 0–8%
  ) +
  scale_fill_brewer(palette = "Set2") +  # Attractive color palette
  theme_minimal(base_size = 14) +  # Minimal theme with larger font
  theme(
    plot.title = element_markdown(size = 18, hjust = 0.5, face = "bold"),  # Styled and centered title
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray50"),  # Subtitle for context
    axis.title.x = element_text(size = 14, face = "bold"),  # Bold X-axis title
    axis.text.x = element_text(size = 12, face = "bold"),  # Bold X-axis text
    axis.text.y = element_text(size = 12, face = "bold"),  # Bold Y-axis text
    axis.title.y = element_blank(),  # Remove Y-axis title for simplicity
    panel.grid.major.x = element_blank(),  # Remove vertical grid lines
    panel.grid.major.y = element_line(color = "gray90", linetype = "dashed"),  # Subtle horizontal grid lines
    plot.caption = element_text(size = 10, hjust = 1, color = "gray50")  # Caption styling
  )
```

The chart displays the percentage of late flights by origin airport, highlighting the proportion of flights arriving more than 15 minutes late.
Each bar represents an origin airport, with the height indicating the percentage of delayed flights.
The highest percentage of late flights is evident at specific airports, emphasizing variations in punctuality influenced by airport-specific factors.
The percentages are clearly labeled, aiding quick interpretation.

```{r}
# Line plot for percentage of flights delayed by day
flights_cleaned %>%
  group_by(day) %>%  # Group by day of the month
  summarize(
    total_flights = n(),  # Total number of flights
    delayed_flights = sum(arr_delay > 15, na.rm = TRUE)  # Count of delayed flights
  ) %>%
  mutate(percentage_delayed = delayed_flights / total_flights) %>%  # Calculate percentage of delayed flights
  ggplot(aes(x = day, y = percentage_delayed)) +
  geom_line(color = "midnightblue", size = 1.2) +  # Line plot with custom color and size
  geom_point(size = 3, color = "red") +  # Add points for emphasis
  scale_y_continuous(labels = label_percent(), limits = c(0, 0.5)) +  # Format Y-axis as percentage
  scale_x_continuous(breaks = seq(1, 31, 1)) +  # X-axis shows all days of the month
  labs(
    title = "<b style='color:#0073C2;'>Percentage of Flights Delayed</b><br><b>By Day of the Month</b>",
    subtitle = "Proportion of flights delayed (>15 minutes) for each day",
    x = "Day of the Month",
    y = "Percentage of Delayed Flights",
      ) +
  theme_minimal(base_size = 14) +  # Minimal theme with larger font
  theme(
    plot.title = element_markdown(size = 18, hjust = 0.5, face = "bold"),  # Styled and centered title
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray50"),  # Subtitle for context
    axis.title.x = element_text(size = 14, face = "bold"),  # Bold X-axis title
    axis.title.y = element_text(size = 14, face = "bold"),  # Bold Y-axis title
    axis.text = element_text(size = 12, face = "bold"),  # Bold axis text
    panel.grid.major = element_line(color = "gray90", linetype = "dashed"),  # Subtle gridlines
    panel.grid.minor = element_blank(),  # Hide minor gridlines
    plot.caption = element_text(size = 10, hjust = 1, color = "gray50")  # Caption styling
  )
```

The line chart illustrates the percentage of flights delayed by day of the month.
The trend fluctuates, with the proportion of delays generally ranging between 20% and 30%.
Peaks on specific days suggest variations in operational or external factors affecting punctuality.
The visualization highlights potential patterns in delays over the month.

```{r}
# Line plot for percentage of flights delayed by season
# Add a 'season' column based on the month
flights_cleaned <- flights_cleaned %>%
  mutate(season = case_when(
    month %in% c(12, 1, 2) ~ "Winter",  # December, January, February
    month %in% c(3, 4, 5) ~ "Spring",  # March, April, May
    month %in% c(6, 7, 8) ~ "Summer",  # June, July, August
    month %in% c(9, 10, 11) ~ "Fall"   # September, October, November
  ))

# Summarize the percentage of flights delayed by season
flights_cleaned %>%
  group_by(season) %>%  # Group by season
  summarize(
    total_flights = n(),  # Total number of flights
    delayed_flights = sum(arr_delay > 15, na.rm = TRUE)  # Count of delayed flights
  ) %>%
  mutate(percentage_delayed = delayed_flights / total_flights) %>%  # Calculate percentage of delayed flights
  ggplot(aes(x = season, y = percentage_delayed, group = 1)) +  # Group to draw a single line
  geom_line(color = "midnightblue", size = 1.2) +  # Line plot with custom color and size
  geom_point(size = 3, color = "red") +  # Add points for emphasis
  scale_y_continuous(labels = label_percent(), limits = c(0, 0.5)) +  # Format Y-axis as percentage
  scale_x_discrete(limits = c("Winter", "Spring", "Summer", "Fall")) +  # Ensure correct seasonal order
  labs(
    title = "<b style='color:#0073C2;'>Percentage of Flights Delayed</b><br><b>By Season</b>",
    subtitle = "Proportion of flights delayed (>15 minutes) for each season",
    x = "Season",
    y = "Percentage of Delayed Flights",
      ) +
  theme_minimal(base_size = 14) +  # Minimal theme with larger font
  theme(
    plot.title = element_markdown(size = 18, hjust = 0.5, face = "bold"),  # Styled and centered title
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray50"),  # Subtitle for context
    axis.title.x = element_text(size = 14, face = "bold"),  # Bold X-axis title
    axis.title.y = element_text(size = 14, face = "bold"),  # Bold Y-axis title
    axis.text = element_text(size = 12, face = "bold"),  # Bold axis text
    panel.grid.major = element_line(color = "gray90", linetype = "dashed"),  # Subtle gridlines
    panel.grid.minor = element_blank(),  # Hide minor gridlines
    plot.caption = element_text(size = 10, hjust = 1, color = "gray50")  # Caption styling
  )

```

The line chart displays the percentage of flights delayed by season.
Delays peak during the summer, with approximately 25% of flights delayed, while the fall has the lowest delay percentage, around 15%.
This seasonal trend reflects variations in factors like weather conditions and travel demand.

```{r}
# Impact of weather on arrival delay

# Step 1: Preprocess weather_clean
# Convert weather variables to numeric by replacing commas with dots and coercing to numeric
weather_clean <- weather_clean %>%
  mutate(
    temp = as.numeric(gsub(",", ".", temp)),  # Convert temp to numeric
    dewp = as.numeric(gsub(",", ".", dewp)),  # Convert dewp to numeric
    humid = as.numeric(gsub(",", ".", humid)),  # Convert humid to numeric
    wind_speed = as.numeric(gsub(",", ".", wind_speed)),  # Convert wind_speed to numeric
    wind_gust = as.numeric(gsub(",", ".", wind_gust)),  # Convert wind_gust to numeric
    precip = as.numeric(gsub(",", ".", precip)),  # Convert precip to numeric
    visib = as.numeric(gsub(",", ".", visib))  # Convert visib to numeric
  )

# Step 2 Merge flights_cleaned and weather_clean
# Join the two datasets by origin and time_hour to align flight and weather data
flights_weather <- flights_cleaned %>%
  left_join(weather_clean, by = c("origin", "time_hour"))

# Step 3 Create a correlation matrix for weather and arrival delay
# Select only relevant numeric columns for the correlation matrix
weather_arr_corr <- flights_weather %>%
  select(arr_delay, temp, dewp, humid, wind_speed, wind_gust, precip, pressure, visib) %>%
  drop_na()  # Remove rows with missing values

# Step 4: Calculate the correlation matrix
cor_matrix_arr <- cor(weather_arr_corr, use = "complete.obs")  # Compute correlations between variables

# Step 5: Visualize full correlation matrix for arrival delay
ggcorrplot(
  cor_matrix_arr,
  lab = TRUE,                     # Display correlation values
  type = "full",                  # Show the full symmetric matrix
  lab_size = 3,                   # Set the size of the labels
  title = "Correlation Matrix: Weather and Arrival Delay",  # Plot title
  colors = c("red", "white", "cyan"),  # New color gradient: green to orange
  legend.title = "Correlation"   # Legend title
)
```

The correlation matrix illustrates the relationships between weather variables and arrival delay.
Most correlations with arr_delay are weak, with humid showing the strongest positive correlation (0.11), indicating higher delays with increased humidity.
Other variables like visib and pressure exhibit minimal or negligible correlation with arrival delays, suggesting limited direct weather impact.
The results highlight that while weather factors contribute, they alone do not heavily dictate delays.\`

## Data Preprocessing

In the preprocessing step, we prepared the dataset for modeling by transforming variables and normalizing numerical features.
We left-joined flights data with weather data using `time_hour` and `origin` as keys.
Rows with missing values in critical weather variables (`wind_speed`, `visib`, `precip`, `temp`) were removed to ensure data quality.
To handle categorical variables, we grouped less significant carriers into an "Other" category for simplicity.
Finally, numerical features such as `distance`, `wind_speed`, `visib`, `precip`, and `temp` were normalized using min-max scaling to improve model performance and comparability across features.

```{r}
#| label: preprocessing
# regression preprocessing
# left join flights_cleaned and weather_clean
flights_weather = flights_cleaned |>
  left_join(weather_clean, by = c("time_hour", "origin"))

# Check for missing values after the join
missing_weather = flights_weather |>
  summarize(across(c(wind_speed, visib, precip, temp), ~ sum(is.na(.))))

# Filter out rows with missing weather data
flights_weather_filtered = flights_weather |>
  filter(!is.na(wind_speed) & !is.na(visib) & !is.na(precip) & !is.na(temp))

# Add part_of_day feature based on sched_dep_time
flights_weather_filtered = flights_weather_filtered |>
  mutate(
    part_of_day = case_when(
      sched_dep_time >= 600 & sched_dep_time < 1200 ~ "Morning",
      sched_dep_time >= 1200 & sched_dep_time < 1800 ~ "Afternoon",
      sched_dep_time >= 1800 & sched_dep_time < 2400 ~ "Evening",
      TRUE ~ "Night"
    )
  )

# character to numeric conversion
flights_weather_filtered = flights_weather_filtered |>
  mutate(
    temp = as.numeric(gsub(",", ".", temp)),
    humid = as.numeric(gsub(",", ".", humid)),
    wind_speed = as.numeric(gsub(",", ".", wind_speed)),
    precip = as.numeric(gsub(",", ".", precip)),
    visib = as.numeric(gsub(",", ".", visib))
  )
# normalizing numerical features
normalize = function(x) {(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))}
flights_preprocessed = flights_weather_filtered |>
  mutate(
    distance_norm = normalize(distance),
    wind_speed_norm = normalize(wind_speed),
    visib_norm = normalize(visib),
    precip_norm = normalize(precip),
    temp_norm = normalize(temp)
  )

set.seed(11111) #repro
train_index = createDataPartition(flights_preprocessed$arr_delay, p = 0.8, list = FALSE)
train_data = flights_preprocessed[train_index, ]
test_data = flights_preprocessed[-train_index, ]
```

## Supervised Learning

### Regression task

For the regression task, we aimed to predict flight arrival delays `arr_delay` based on various features, including flight `distance`, weather conditions, and `carrier` information.
Our goal was to build and evaluate a regression model that could identify the key factors contributing to delays and provide reasonable predictions.
We explored feature engineering, refined our model by addressing multicollinearity and insignificant predictors, and assessed its performance using metrics like *RMSE* and *MAE* to ensure practical insights.

```{r}
#| label: regression-initial
# creating the initial regression model
reg_model = lm(arr_delay ~ distance_norm + wind_speed_norm + visib_norm + precip_norm + temp_norm + carrier + part_of_day, data = train_data)

tidy(reg_model)
glance(reg_model)
```

```{r}
#| label: regression-refined
# Re-split the dataset after modifying the carrier variable
set.seed(11111)
train_index = createDataPartition(flights_preprocessed$arr_delay, p = 0.8, list = FALSE)
train_data = flights_preprocessed[train_index, ]
test_data = flights_preprocessed[-train_index, ]

# Recode the carrier variable, grouping insignificant carriers into "Other"
significant_carriers = c("AA", "B6", "F9", "HA", "NK", "YX")
flights_preprocessed = flights_preprocessed |>
  mutate(carrier = ifelse(carrier %in% significant_carriers, carrier, "Other"))

# Fit the refined regression model with significant variables
reg_model_refined = lm(arr_delay ~ distance_norm + visib_norm + temp_norm + carrier + part_of_day, data = train_data)
tidy(reg_model_refined)
glance(reg_model_refined)
```

```{r}
#| label: regression-interaction
# Fit a regression model with interaction terms.
reg_model_interaction = lm(arr_delay ~ distance_norm * part_of_day + visib_norm * temp_norm, data = train_data)
tidy(reg_model_interaction)
glance(reg_model_interaction)
```

```{r}
#| label: regression-metrics
# model evaluation
predictions = predict(reg_model_refined, newdata = test_data)

# metrics and stats
rmse = sqrt(mean((predictions - test_data$arr_delay)^2, na.rm = TRUE))
mae = mean(abs(predictions - test_data$arr_delay), na.rm = TRUE)
r_squared = 1 - sum((predictions - test_data$arr_delay)^2) / sum((test_data$arr_delay - mean(test_data$arr_delay, na.rm = TRUE))^2)

cat("RMSE =", rmse, "\n")
cat("MAE =", mae, "\n")
cat("R-squared =", r_squared, "\n")
```

### Classification task

#Question 1: Predicting Late Arrivals Based on Departure Conditions

```{r}
#| label: preprocessing_classification

# Ensure target variable is a binary factor
flights_cleaned <- flights_cleaned %>%
  mutate(is_late = as.factor(is_late))

# Handle missing values for critical columns
flights_cleaned <- flights_cleaned %>%
  drop_na(dep_delay, sched_dep_time, distance, air_time, is_late)

# Engineer time-based features
flights_cleaned <- flights_cleaned %>%
  mutate(
    dep_hour = sched_dep_time %/% 100,       # Extract departure hour
    dep_minute = sched_dep_time %% 100,     # Extract departure minute
    dep_time_of_day = case_when(            # Categorize time of day
      dep_hour >= 5 & dep_hour < 12 ~ "Morning",
      dep_hour >= 12 & dep_hour < 18 ~ "Afternoon",
      dep_hour >= 18 & dep_hour < 23 ~ "Evening",
      TRUE ~ "Night"
    )
  )

# Encode categorical variables using one-hot encoding
flights_encoded <- fastDummies::dummy_cols(
  flights_cleaned,
  select_columns = c("origin", "carrier", "dep_time_of_day"),
  remove_first_dummy = TRUE
)

# Scale numeric variables for consistent range
flights_encoded <- flights_encoded %>%
  mutate(across(c(dep_delay, distance, air_time, dep_hour, dep_minute), scale))

# Create interaction terms and polynomial features
flights_encoded <- flights_encoded %>%
  mutate(
    distance_airtime_ratio = distance / air_time,  # Interaction feature
    dep_delay_squared = dep_delay^2,              # Polynomial feature
    distance_squared = distance^2                 # Polynomial feature
  )

# Remove zero-variance predictors
zero_variance_features <- nearZeroVar(flights_encoded, saveMetrics = TRUE)
flights_encoded <- flights_encoded %>%
  select(-any_of(names(zero_variance_features[zero_variance_features$zeroVar, ])))

# Split the dataset into training and testing sets
set.seed(123)
train_index <- caret::createDataPartition(flights_encoded$is_late, p = 0.8, list = FALSE)
train_data <- flights_encoded[train_index, ]
test_data <- flights_encoded[-train_index, ]

# Verify the structure of training and testing sets
str(train_data)
str(test_data)

```

```{r}
#| label: classification model

# Fit logistic regression model with selected features
log_model <- glm(
  is_late ~ dep_delay + distance + air_time + origin_JFK + origin_LGA + carrier_DL + carrier_AA + 
            dep_time_of_day_Evening + dep_time_of_day_Night + 
            distance_airtime_ratio + dep_delay_squared + distance_squared, 
  data = train_data, 
  family = "binomial"
)

# Summarize the model
summary(log_model)

# Predict on test data
log_probs <- predict(log_model, test_data, type = "response")
log_preds <- ifelse(log_probs > 0.5, "Late", "OnTime")

# Ensure test_data$is_late is a factor with correct labels
test_data$is_late <- factor(test_data$is_late, levels = c("0", "1"), labels = c("OnTime", "Late"))

# Ensure log_preds has matching levels
log_preds <- factor(log_preds, levels = c("OnTime", "Late"))

# Compute the confusion matrix
conf_matrix <- caret::confusionMatrix(log_preds, test_data$is_late, positive = "Late")
print(conf_matrix)

# AUC-ROC
roc_curve <- roc(as.numeric(test_data$is_late == "Late"), log_probs)
plot(roc_curve, col = "blue", lwd = 2, main = "ROC Curve: Logistic Regression Model")
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")

# Confusion Matrix
conf_matrix <- caret::confusionMatrix(as.factor(log_preds), test_data$is_late, positive = "Late")
print(conf_matrix)

# AUC-ROC
roc_curve <- roc(test_data$is_late, log_probs)
plot(roc_curve, col = "blue", lwd = 2, main = "ROC Curve: Logistic Regression Model")
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

The ROC curve evaluates the performance of the logistic regression model in predicting flight delays.
The Area Under the Curve (AUC) measures the model's ability to distinguish between delayed and on-time flights.
A high AUC indicates good predictive accuracy, with the curve significantly above the diagonal line (random guess).
This visualization highlights the model's effectiveness in classification tasks.

## Insights and Discussion

**Model Performance Comparison:** The regression and classification models demonstrated varying levels of effectiveness in addressing the research questions.
The regression model predicted flight arrival delays with moderate accuracy, as evaluated using metrics such as RMSE and MAE.
It identified key contributors to delays, including departure delay, distance, and specific time-of-day variables.
However, the inherent variability and noise in the dataset limited the model's precision.

The logistic regression model for classification performed well, achieving an AUC of 0.878, indicating strong discrimination between on-time and delayed flights.
The confusion matrix revealed a balanced accuracy of 87.8%, with high sensitivity and specificity, highlighting the model's effectiveness in correctly identifying delayed flights without compromising on-time predictions.

**Key Findings and Insights:**

*Impact of Departure Delays:* Both models consistently identified departure delay as the most significant predictor of arrival delay, emphasizing its cascading effect on subsequent flights.

*Weather Influence:* Correlation analysis showed a modest relationship between weather variables (e.g., humidity) and delays, but their overall contribution to the models was minimal.

*Seasonal Trends:* Delays peaked during the summer, likely due to increased air traffic and weather disruptions, while fall had the lowest delay rates.

*Airline Variability:* Airlines differed significantly in their punctuality, with Allegiant Air performing best and Frontier Airlines facing the highest delays, as reflected in EDA visualizations.

*Destination-Specific Delays:* Certain destinations, such as Ponce (PSE), experienced higher average delays, indicating potential operational or environmental challenges.

**Limitations:** *Data Quality:* Despite data cleaning efforts, missing and imputed values for critical variables may have introduced biases, particularly for weather-related predictors.

*Exclusion of Categorical Features:* Some categorical variables, like specific flight routes or events, were simplified, which may have overlooked complex relationships.

*Temporal Scope:* The analysis is limited to a specific year (2023), potentially reducing generalizability to other time-frames with different traffic or weather patterns.

*Complex Interactions:* The models primarily captured linear relationships, which might not fully represent the nonlinear or interactive effects present in the data.

In conclusion, while the models provided valuable insights into factors influencing flight delays and showed reasonable predictive power, addressing these limitations and incorporating more granular data could further enhance their performance and utility for real-world applications.
